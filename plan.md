# プロジェクト計画: Streaming Conformerによるリアルタイム・モールス信号デコーダー

## 1. プロジェクト概要
**目標:** ディープラーニング・アプローチを用いたリアルタイム・モールス信号 (CW) 復号システムを開発すること。最終的にはWebブラウザ上（WASM/WebGPU）で動作させることを目指す。

**核となる要件:**
- **アーキテクチャ:** CTC損失を用いたStreaming Conformer (CNN + Transformer)。
- **レイテンシ:** ライブ無線運用に適したリアルタイム処理。
- **堅牢性:** HF帯の伝搬アーティファクト（フェージング/QSB、ノイズ/QRN、混信/QRM）および人間の打鍵の揺らぎ（Human Keying Artifacts）を含む信号を復号できること。
- **ターゲット:** Webブラウザ (onnxruntime-web) での動作を見据えた軽量設計。

---

## 2. システムアーキテクチャ

### 2.1 入力パイプライン: 周波数クロッピング戦略
広帯域の信号からターゲット信号を切り出して軽量モデルに入力する「クロッピング戦略」を採用する。

1.  **ソース:** オーディオストリーム (16kHz または 8kHz)。
2.  **スペクトログラム変換:**
    *   `n_mels`: 80
    *   `n_fft`: 400 (25ms)
    *   `hop_length`: 160 (10ms)
3.  **ピーク検出 & クロッピング:**
    *   DSP（FFTピーク検出）により信号が存在する中心周波数を特定。
    *   その中心周波数周辺（例: ±50Hz〜100Hz）の帯域のみを切り出し（クロッピング）、モデルへの入力とする。
    *   これにより、シングルターゲット受信だけでなく、複数ピークを検出すればマルチバンド受信も可能となる。

### 2.2 モデルアーキテクチャ: Lightweight Streaming Conformer
高速CW（40WPM超）に対応しつつ、ブラウザ動作可能な軽量性を確保する。

*   **時間分解能の確保:**
    *   **フレームレート:** 20ms / frame をターゲットとする。
    *   **フロントエンド:** 畳み込みサブサンプリング (Convolution Subsampling)
        *   ストライド2を持つ1層CNN、またはストライド(2,1)の組み合わせなど、**合計ダウンサンプリング率を2倍（時間方向）に留める**。
        *   理由: 40WPMの短点（約30ms）を消失させず、リズムを捉えるため。
*   **エンコーダー:** Conformerブロック (小規模構成: 4~6層)
    *   **Feed Forwardモジュール:** Swish活性化関数。
    *   **Multi-Head Self-Attention (MHSA):**
        *   **因果マスキング (Causal Masking):** リアルタイム性を確保。
        *   **先読みコンテキスト (Look-ahead Context):** 信号の曖昧性解決のため、小さな右コンテキストを許可。
        *   **相対位置エンコーディング (Relative Positional Encoding):** 速度変動（WPMの変化）対応。
*   **デコーダー / 出力:**
    *   CTC Head (Linear -> Softmax)。

### 2.3 トークン化（語彙）
*   **戦略:** 文字 + サブワード (BPE) のハイブリッド、または文字ベース。
*   **語彙リスト:**
    *   標準: `[A-Z]`, `[0-9]`, `/`, `?`, `.`, `,`
    *   特殊トークン: `<blank>` (CTC要件), `<space>` (単語境界)。
    *   プロサイン/頻出語: `<BT>`, `<AR>`, `<SK>`, `CQ`, `DE`, `599`。

---

## 3. データ戦略（合成生成）
実際のラベル付きデータは希少であるため、物理現象と人間特性の両方を模倣した**高度な合成データジェネレータ**を構築する。

### 3.1 基本信号生成と人間的揺らぎ (Human Keying Artifacts)
機械的な正確さに加え、人間特有の「クセ」をシミュレートする。
*   **手送り (Straight Key):** 短点・長点の長さのランダムなばらつき。
*   **バグキー (Bug Key):** 短点は機械的だが、長点の長さが手動制御で不安定になる特性。
*   **ウェイト (Weighting) 変動:** 短点:長点の比率を標準の 1:3 から動的に変化させる（例: 1:3.5, 1:2.8）。
*   **速度:** 10 WPM 〜 50 WPM。

### 3.2 信号劣化（HFチャネルシミュレータ）
1.  **フェージング (QSB):** レイリーフェージング、ドップラー広がり。
2.  **ノイズ (QRN):** ガウスノイズ、インパルスノイズ（雷/イグニッション）。
3.  **混信 (QRM):** 近接周波数のビート干渉。
4.  **信号歪み:** バンドパスフィルタのリンギング、周波数ドリフト(QRH)、ハム音。

---

## 4. 実装ステップ

### フェーズ 1: データジェネレータ実装
*   **タスク:** `data_gen.py` の作成。
*   **要件:**
    *   人間的な揺らぎ（手送り、バグキー）の実装。
    *   DSP効果（フェージング、ノイズ）の実装。
    *   PyTorch Datasetとしてのカプセル化。

### フェーズ 2: モデル定義と学習
*   **タスク:** `model.py`, `train.py` の作成。
*   **要件:**
    *   20ms分解能（ダウンサンプリング2倍）のStreaming Conformer実装。
    *   オンザフライデータ生成による学習。
    *   ONNXエクスポートの検証（動的軸のサポート確認）。

### フェーズ 3: リアルタイム推論エンジン (Pythonプロトタイプ)
*   **タスク:** `stream_decode.py` の作成。
*   **要件:**
    *   PyAudio等による音声入力。
    *   **DSP前処理:** ピーク検出と周波数クロッピングの実装。
    *   ONNX Runtimeによる推論ループ。

### フェーズ 4: Webブラウザデプロイ (最終目標)
*   **タスク:** Webアプリケーション化。
*   **要件:**
    *   Web Audio APIによるマイク入力とスペクトログラム生成。
    *   WASMによる信号処理（ピーク検出・切り出し）。
    *   `onnxruntime-web` (WASM/WebGPU) によるブラウザ内推論。

---

## 5. 技術スタック
*   **学習:** Python 3.10+, PyTorch 2.x, Torchaudio
*   **信号処理:** NumPy, SciPy
*   **推論 (Python):** ONNX Runtime
*   **推論 (Web):** onnxruntime-web, Web Audio API, JavaScript/TypeScript