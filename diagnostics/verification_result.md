# 入力解像度の検証結果

## 概要
ユーザーからの指摘「MとKは現在の解像度でも区別できるはずだ」を検証するため、`diagnostics/verify_resolution.py` を作成し、実際の入力特徴量（Mel-Spectrogram）を可視化・分析しました。

## 結果
*   **可視化画像**: `diagnostics/resolution_check.png` に保存。
*   **数値解析**:
    *   **M (Dash, Dash)**: 2つの明確なエネルギーピークを検出。
    *   **K (Dash, Dot, Dash)**: 3つの明確なエネルギーピークを検出。
*   **結論**: **現在の入力解像度（N_FFT=400, HOP=160）で、20 WPM の信号を区別することは十分に可能です。**

## 考察と修正方針
入力特徴量の段階では情報は失われていません。しかし、学習は停滞しています。
これは、問題が「入力の情報量」ではなく、**「モデルがその情報を活用できていない」** 点にあることを示唆しています。

特に疑わしいのは以下の2点です。

1.  **サブサンプリングによる情報の損失**:
    *   入力段階では見えていても、モデル内部の `ConvSubsampling` (stride=2) によって時間軸が 1/2 に圧縮された際、短い Dot が「潰れて」しまっている可能性があります。
    *   対策: **サブサンプリングを廃止する (Stride=1)**。

2.  **Blank Collapse (アライメントの失敗)**:
    *   モデルは入力が見えていても、初期の学習段階で「Blankを出力する」という安易な局所解に陥っています。
    *   対策: **CTC Head の初期バイアスを強力に調整し、Blankの出力を抑制する**。

## 修正プラン (Revised)
当初の計画から「入力解像度 (N_FFT/HOP) の変更」を除外し、モデル内部の修正に集中します。

1.  **`config.py`**:
    *   `SUBSAMPLING_RATE`: 2 -> **1** (変更)
    *   `N_FFT`, `HOP_LENGTH`: **変更なし** (現状維持)

2.  **`model.py`**:
    *   `ConvSubsampling`: Stride=1 に対応させる。
    *   `StreamingConformer`: CTC Head の Blank 初期バイアスを `-1.0` -> **-5.0** に変更。

3.  **`train.py`**:
    *   カリキュラムをリセットし、学習を最初からやり直す。